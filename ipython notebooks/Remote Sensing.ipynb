{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import shutil\n",
    "import urllib2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "\n",
    "from urllib2 import urlopen     \n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pylab import rcParams\n",
    "import platform\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import re\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import urllib\n",
    "\n",
    "import gzip\n",
    "\n",
    "import ftplib\n",
    "import calendar\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import pymodis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "arcpy.CheckOutExtension(\"spatial\")\n",
    "#from arcpy import env \n",
    "from arcpy.sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System Windows 7\n",
      "Python Version 2.7.10 (default, May 23 2015, 09:44:00) [MSC v.1500 64 bit (AMD64)]\n",
      "Pandas Version 0.19.2\n",
      "Numpy Version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Operating System \" + platform.system() + \" \" + platform.release())\n",
    "print(\"Python Version \" + str(sys.version))\n",
    "print(\"Pandas Version \" + str(pd.__version__))\n",
    "print(\"Numpy Version \" + str(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIS16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential and Actual Evapotranspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lucadelu/pyModis/blob/master/docs/source/examples/pyModis.ipynb<br>\n",
    "http://www.ntsg.umt.edu/project/mod16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest = 'H:/GIS/MODIS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download HDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script automatically retrieves monthly MODIS16 hdf file from the ntsg website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Download HDF Files\n",
    "#'h09v05','h09v04','h08v05'\n",
    "tiles = ['h09v05','h09v05','h09v04','h08v05']\n",
    "save_path = 'H:/GIS/MODIS2/'\n",
    "\n",
    "\n",
    "def get_modis(tiles, save_path, months='', years=''):\n",
    "\n",
    "    if months == '':\n",
    "        months = [1,12]\n",
    "    if years == '':\n",
    "        years = [2000,2015]\n",
    "\n",
    "    mons = [str(i).zfill(2) for i in range(months[0],months[1]+1)]\n",
    "    yrs = [str(i) for i in range(years[0],years[1]+1)]\n",
    "\n",
    "    for tile in tiles:\n",
    "        for yr in yrs:\n",
    "            for m in mons:\n",
    "                base_url = \"http://files.ntsg.umt.edu/data/NTSG_Products/MOD16/MOD16A2_MONTHLY.MERRA_GMAO_1kmALB/\"\n",
    "\n",
    "                dir_path = \"Y{:}/M{:}/\".format(yr,m)\n",
    "                url = base_url+dir_path\n",
    "                soup=BeautifulSoup(urlopen(url),\"lxml\")\n",
    "                hdf_name = soup.find_all('', {'href':re.compile('MOD16A2.A{:}M{:}.{:}.105'.format(yr,m,tile), re.IGNORECASE)})\n",
    "                files = urllib.urlretrieve(url+hdf_name[0].text, save_path + hdf_name[0].text)\n",
    "                print(save_path+hdf_name[0].text)\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "get_modis(tiles, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path = 'H:/GIS/MODIS2/'\n",
    "files = glob.glob(os.path.join(save_path, '*.105*.hdf'))\n",
    "\n",
    "def get_file_list(save_path):\n",
    "    return glob.glob(os.path.join(save_path, '*.105*.hdf'))\n",
    "\n",
    "get_file_list(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproject MODIS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts reproject the hdf files from the <a href=\"https://modis-land.gsfc.nasa.gov/MODLAND_grid.html\">wacky sinusoidal MODIS projection</a> to <a href=\"http://spatialreference.org/ref/epsg/4269/\">NAD83 Zone 12</a> for analysis.  In this section, the MODIS rasters are also clipped to Utah Watersheds (see image below) and the fill values are made to null values. Fill values are described in the <a href=\"http://files.ntsg.umt.edu/data/NTSG_Products/MOD16/MOD16_global_evapotranspiration_description.pdf\">MODIS16 documentation</a>:\n",
    "<br>\n",
    "<ul>\n",
    "<li>Fill value, out of the earth 32767</li>\n",
    "<li>Water body 32766</li>\n",
    "<li>Barren or sparsely vegetated 32765</li> \n",
    "<li>Permanent snow and ice 32764</li>\n",
    "<li>Permanent wetland 32763</li>\n",
    "<li>Urban or Built-up 32762</li>\n",
    "<li>Unclassified 32761</li>\n",
    "<img src=\"https://cfpub.epa.gov/surf/images/states/ut.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EPSG code for NAD83 Zone 12 is 26912."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reprojectMODIS(files,save_path,data_type,proj=26912):\n",
    "    \"\"\"Iterates through MODIS files in a folder reprojecting them. \n",
    "    \n",
    "    Takes the crazy MODIS sinusoidal projection to a user defined projection.\n",
    "    \n",
    "    Args:\n",
    "        files: list of file paths of MODIS hdf files; created using files = glob.glob(os.path.join(save_path, '*.105*.hdf'))\n",
    "        save_path: folder to store the reprojected files\n",
    "        data_type: type of MODIS16 data being reprojected; options are 'ET','PET','LE', and 'PLE'\n",
    "        \n",
    "    Returns:\n",
    "        Reprojected MODIS files\n",
    "        \n",
    "    \"\"\"\n",
    "    # dictionary to designate a directory\n",
    "    datadir = {'ET':'/ET/','PET':'/PET/','LE':'/LE/','PLE':'/PLE/'}\n",
    "    # dictionary to select layer from hdf file that contains the datatype\n",
    "    matrdir = {'ET':[1,0,0,0], 'LE':[0,1,0,0], 'PET':[0,0,1,0], 'PLE':[0,0,0,1]}\n",
    "    \n",
    "    # check for file folder and make it if it doesn't exist\n",
    "    if not os.path.exists(save_path + datadir[data_type]):\n",
    "        os.makedirs(save_path + datadir[data_type])\n",
    "        print('created {:}'.format(save_path + datadir[data_type]))\n",
    "    \n",
    "    \n",
    "    for f in files:\n",
    "        year = f.split('\\\\')[1].split('.')[1][1:5] # parse year from hdf filename\n",
    "        month = f.split('\\\\')[1].split('.')[1][-2:] # parse month from hdf filename\n",
    "        v = f.split('\\\\')[1].split('.')[2][-2:] # parse v (cell coordinate) from hdf filename\n",
    "        h = f.split('\\\\')[1].split('.')[2][1:3] # parse h (cell coordinate) from hdf filename\n",
    "        pref = os.path.join(save_path+datadir[data_type]+'A'+ year+'M'+ month +'h'+ h + 'v' + v)\n",
    "        convertsingle = pymodis.convertmodis_gdal.convertModisGDAL(hdfname=f, prefix=pref, \n",
    "                                                                   subset = matrdir[data_type], \n",
    "                                                                   res=1000, epsg=proj)\n",
    "        #[ET,LE,PET,PLE]\n",
    "        try:\n",
    "            convertsingle.run()\n",
    "        except:\n",
    "            print('A'+ year+'M'+ month +'h'+ h + 'v' + v + ' failed!')\n",
    "            pass\n",
    "\n",
    "def clipandfix(path, outpath, data_type, area = ''):\n",
    "    \"\"\"Clips raster to Utah's Watersheds and makes exception values null.\n",
    "    \n",
    "    Args:\n",
    "        path: folder of the reprojected MODIS files\n",
    "        outpath: ESRI gdb to store the clipped files\n",
    "        data_type: type of MODIS16 data being reprojected; options are 'ET','PET','LE', and 'PLE'\n",
    "    \n",
    "    \"\"\"\n",
    "    # Check out the ArcGIS Spatial Analyst extension license\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    if area == '':\n",
    "        area = 'H:/GIS/NHD_UT_Proj.gdb/UT_HUC_area'\n",
    "    \n",
    "    arcpy.env.mask = area\n",
    "\n",
    "    for rast in arcpy.ListRasters():\n",
    "        calc = SetNull(arcpy.Raster(rast) > 32760, arcpy.Raster(rast)) \n",
    "        calc.save(outpath+data_type+rast[1:5]+rast[6:8]+'h'+rast[10:11]+'v'+rast[13:14])\n",
    "        print(outpath+data_type+rast[1:5]+rast[6:8]+'h'+rast[10:11]+'v'+rast[13:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprojectMODIS(files,save_path,'ET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"H:/GIS/MODIS2/ET/\"\n",
    "outpath=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "clipandfix(path,outpath,'ET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path = \"H:/GIS/MODIS2/PET/\"\n",
    "reprojectMODIS(files,save_path,'PET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"H:/GIS/MODIS2/PET/\"\n",
    "outpath=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "clipandfix(path,outpath,'PET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIS data is downloaded as separate cells based on the Sinusoidal grid.  Three MODIS cells cover Utah ('h09v05','h09v04','h08v05'). The following scripts mosaic (merge) the three individual rasters for each month into one seamless monthly raster for the entire state. \n",
    "<img src=\"https://modis-land.gsfc.nasa.gov/images/MODIS_sinusoidal_grid1.gif\" alt=\"MODIS grid\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeRasts(path, data_type = 'ET', monthRange = [1,12], yearRange = [2000,2014]):\n",
    "    \"\"\"Mosaics (merges) different MODIS cells into one layer.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    arcpy.env.workspace = path\n",
    "    outCS = arcpy.SpatialReference('NAD 1983 UTM Zone 12N')\n",
    "    for y in range(yearRange[0],yearRange[-1]+1): #set years converted here\n",
    "        for m in range(monthRange[0],monthRange[-1]+1): #set months converted here   \n",
    "            nm = data_type + str(y) + str(m).zfill(2)\n",
    "            rlist=[]\n",
    "            for rast in arcpy.ListRasters(nm+'*'): \n",
    "                rlist.append(rast)\n",
    "            try:\n",
    "                arcpy.MosaicToNewRaster_management(rlist,path,nm+'c',outCS,\\\n",
    "                                                   \"16_BIT_UNSIGNED\",\"1000\",\"1\",\"LAST\",\"LAST\")\n",
    "            \n",
    "                print(path+nm+'c')\n",
    "            except:\n",
    "                print(nm+' failed!')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "mergeRasts(path,data_type='ET', monthRange = [1,12], yearRange = [2011,2014])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "mergeRasts(path,data_type='PET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale MODIS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the dataset says that the raw files have to be multiplied by 0.1 to get mm/month.  To convert to meters per month, we have to multiply the raw files by 0.0001 (0.1 x 0.001) or divide by 10,000.  These scripts do that division. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_MODIS(path, out_path, scaleby = 10000.0, data_type = 'ET', monthRange = [1,12], yearRange = [2000,2014]):\n",
    "    for y in range(yearRange[0],yearRange[-1]+1): #set years converted here\n",
    "        for m in range(monthRange[0],monthRange[-1]+1): #set months converted here\n",
    "            nm = data_type + str(y) + str(m).zfill(2)\n",
    "            calc = Divide(nm + 'c', scalingFactor)\n",
    "            calc.save(out_path+nm)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "arcpy.env.workspace = path\n",
    "\n",
    "scalingFactor = 10000.0 #convert to m/month\n",
    "out_path=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "\n",
    "scale_MODIS(path, out_path, scaleby = 10000.0, data_type = 'ET')\n",
    "scale_MODIS(path, out_path, scaleby = 10000.0, data_type = 'PET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up GDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deletes intermediate files left over from previous processing steps. For whatever reason, it take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "arcpy.env.workspace = path\n",
    "\n",
    "for rast in arcpy.ListRasters('*c'):\n",
    "    print(rast)\n",
    "    arcpy.Delete_management(rast, 'RasterDataset')\n",
    "    \n",
    "#for rast in arcpy.ListRasters('*h*v*'):\n",
    "#    print(rast)\n",
    "#    arcpy.Delete_management(rast, 'RasterDataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Holes in Rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processing step fills in null values created when the fill values were removed [above](#Reproject-MODIS-Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: http://gis.stackexchange.com/questions/136075/fill-in-nodata-gaps-in-raster-using-arcgis-for-desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path= \"H:/GIS/MODIS2/MODIS.gdb/\"\n",
    "outpath = \"H:/GIS/MODIS2/MODIS16.gdb/\"\n",
    "\n",
    "units = 'CELL'\n",
    "radius = 15\n",
    "\n",
    "arcpy.env.workspace = path\n",
    "\n",
    "def fill_holes(path, outpath, wildcard, units='CELL', radius=15):\n",
    "    for rast in arcpy.ListRasters(wildcard):\n",
    "        rfilled = arcpy.sa.Con(arcpy.sa.IsNull(rast),\n",
    "                              arcpy.sa.FocalStatistics(rast,\n",
    "                                                       arcpy.sa.NbrCircle(radius, units),'MEAN'), rast)\n",
    "        dsc = arcpy.Describe(rast)\n",
    "        nm = dsc.baseName\n",
    "        rfilled.save(outpath+nm)\n",
    "        print(nm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNODAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were downloaded using polaris: http://nsidc.org/data/polaris/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can download from the ftp, which is slower. <br>\n",
    "ftp://sidads.colorado.edu/pub/DATASETS/NOAA/G02158/ <br>\n",
    "https://support.nsidc.org/entries/64231694-FTP-Client-Data-Access "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SNODAS TARs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = u'H:\\GIS\\SNODAS'\n",
    "def get_snodas(out_file,months='',years=''):\n",
    "    if months == '':\n",
    "        months = [1,12]\n",
    "    if years == '':\n",
    "        years = [2000,2015]\n",
    "\n",
    "    monnames = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    mons = [str(i).zfill(2) + \"_\" + monnames[i-1] for i in range(months[0],months[1]+1)]\n",
    "\n",
    "    yrs = [str(i) for i in range(years[0],years[1]+1)]\n",
    "\n",
    "    for yr in yrs:\n",
    "        for m in mons:\n",
    "            ftp_addr = \"sidads.colorado.edu\"\n",
    "            ftp = ftplib.FTP(ftp_addr)\n",
    "            ftp.login()\n",
    "\n",
    "            dir_path = \"pub/DATASETS/NOAA/G02158/masked/\" + yr + \"/\" + m + \"/\"\n",
    "            ftp.cwd(dir_path)\n",
    "            files = ftp.nlst()\n",
    "\n",
    "            for f in files:\n",
    "                if len(f) > 4:\n",
    "                    save_file = open(L + \"/\" + f,'wb')\n",
    "                    ftp.retrbinary(\"RETR \"+f, save_file.write)\n",
    "                    save_file.close()\n",
    "                    print(f)\n",
    "            ftp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract SNODAS Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>http://nsidc.org/data/docs/noaa/g02158_snodas_snow_cover_model/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://github.com/PSU-CSAR/SNODAS-SWE/blob/master/snodas-swe-prep.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unzip tar files and put in unzip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snodasTars = glob.glob(u'H:/GIS/SNODAS/*.tar')\n",
    "for tared in snodasTars:\n",
    "    untar(tared,u'H:/GIS/SNODAS/SNODASUNZIPPED/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ungz gz files and delete gz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unsnodasTars = glob.glob(u'H:/GIS/SNODAS/SNODASUNZIPPED/*.gz')\n",
    "for tared in unsnodasTars:\n",
    "    ungz(tared, deletesource=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace header file to make compatible with ArcGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for hdrfile in glob.glob(\"H:/GIS/SNODAS/SNODASUNZIPPED/*.Hdr\"):\n",
    "    replace_hdr_file(hdrfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polaris Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded data from http://nsidc.org/data/polaris/, which allows for clipping to an area, as well as output as GeoTiff Format.  The download takes about 3 days and the unzipping takes about 2 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Extent:</b><br>\n",
    "<ul type=\"disc\">\n",
    "<li>Top `44.0254000046`</li>\n",
    "<li>Left `-116.075366662`</li>\n",
    "<li>Right `-108.375366657`</li>\n",
    "<li>Bottom `36.0087333333`</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Selected Variables:</b> <p>Snow Melt Runoff at the Base of the Snow Pack, Sublimation of Blowing Snow, Snow Pack Average Temperature, Sublimation from the Snow Pack, Snow Water Equivalent, Liquid Precipitation, Snow Depth, Solid Precipitation</p><br>\n",
    "<b>Download Format:</b> GeoTIFF<br>\n",
    "<b>Output Grid:</b> 30\" (Cylindrical Equidistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After unzipping files, rename them to make them easier to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From http://nsidc.org/data/docs/noaa/g02158_snodas_snow_cover_model/, the file abbreviations are as follows:\n",
    "<ul type=\"disc\">\n",
    "<li>`RAIN` = `Wet Precip`</li>\n",
    "<li>`SWEQ` = `Snow Water Equivalent`</li> \n",
    "<li>`SNOD` = `Snow Depth`</li> \n",
    "<li>`SPAT` = `Snow Pack Average Temp`</li>\n",
    "<li>`BSSB` = `Blowing Snow Sublimation`</li>\n",
    "<li>`SNML` = `Snowmelt`</li>\n",
    "<li>`SPSB` = `Snow Pack Sublimation`</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_polaris_snodas(path):\n",
    "    prodcode = {'us_ssmv11038wS__A':'SPAT', 'us_ssmv11044bS__T':'SNML', 'us_ssmv11050lL00T':'SPSB', \n",
    "                'us_ssmv11034tS__T':'SWEQ', 'us_ssmv01025SlL00':'RAIN', 'us_ssmv01025SlL01':'SNOW',\n",
    "                'us_ssmv11036tS__T':'SNOD', 'us_ssmv11039lL00T':'BSSB'}\n",
    "\n",
    "    #path = \"H:/GIS/SNODAS/SNWDS\"\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.startswith(\"us_ssmv\"):\n",
    "            code = prodcode[filename[0:17]]\n",
    "            yrsrt = filename.find('TNATS') + 5\n",
    "            yr = filename[yrsrt:yrsrt+4]\n",
    "            mo = filename[yrsrt+4:yrsrt+6]\n",
    "            dy = filename[yrsrt+6:yrsrt+8]\n",
    "            try:\n",
    "                os.rename(os.path.join(path, filename), os.path.join(path,code+yr+mo+dy+filename[-4:]))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "path = \"C:/Users/PAULINKENBRANDT/Downloads/NSIDC_Data\"           \n",
    "rename_polaris_snodas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merge (daily to monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This merge uses geoTiff files from Polaris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "https://pro.arcgis.com/en/pro-app/help/analysis/spatial-analyst/mapalgebra/building-complex-statements.htm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def snowsummary(code, scalingFactor, statistics=\"SUM\", outcellsize = '1000',monthRange = [1,12], yearRange = [2003,2016], \n",
    "                path=\"H:/GIS/SNODAS/SNWDS/\", outpath=\"H:/GIS/SNODAS.gdb/\"):\n",
    "    '''\n",
    "    summarizes daily SNODAS data to monthly values\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    code = text; prefix of dataset to use; choices are 'RAIN','SWEQ','SNOD','SPAT','BSSB','SNML', or 'SPSB'\n",
    "    scalingFactor = float; table 1 at http://nsidc.org/data/docs/noaa/g02158_snodas_snow_cover_model/\n",
    "    statistics = text; from arcpy sa CellStatistics; choices are MEAN, MAJORITY, MAXIMUM, MEDIAN, MINIMUM, MINORITY, \n",
    "                    RANGE, STD, SUM, or VARIETY\n",
    "    monthRange = len 2 list; begin and end month of data you wish to analyze\n",
    "    yearRange = len 2 list; bengin and end year of data you wish to analyze\n",
    "    path = directory where raw geoTiffs are located\n",
    "    outpath = directory where final data will be stored\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    projected and scaled monthly rasters\n",
    "\n",
    "    '''\n",
    "    g = {}\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    \n",
    "    statstype = {'MEAN':'AVG', 'MAJORITY':'MAJ', 'MAXIMUM':'MAX', 'MEDIAN':'MED', 'MINIMUM':'MIN', 'MINORITY':'MNR', \n",
    "                 'RANGE':'RNG', 'STD':'STD', 'SUM':'SUM', 'VARIETY':'VAR'}\n",
    "\n",
    "    for y in range(yearRange[0],yearRange[1]+1): #set years converted here\n",
    "        for m in range(monthRange[0],monthRange[1]+1): #set months converted here\n",
    "            g[code+str(y)+str(m).zfill(2)] = [] #this defines the dictionary key based on data type month and year\n",
    "            for name in sorted(glob.glob(path+code+'*.tif')): #pick all tiff files from raw data folder of a data type\n",
    "                rast = os.path.basename(name) \n",
    "                if rast[0:4] == code and int(rast[4:8]) == y and int(rast[8:10]) == m:\n",
    "                    g[code+str(y)+str(m).zfill(2)].append(rast) #create a list of rasters for each month\n",
    "                else:\n",
    "                    pass\n",
    "            if len(g[code+str(y)+str(m).zfill(2)])>0:\n",
    "                print(g[code+str(y)+str(m).zfill(2)])\n",
    "                # arcpy sa functions that summarize the daily data to monthly data\n",
    "                calc = CellStatistics(g[code+str(y)+str(m).zfill(2)], statistics_type = statistics, ignore_nodata=\"DATA\")\n",
    "                calc = Divide(calc, scalingFactor) #scale factor, converts to kg/m2 10 then to m 0.001\n",
    "                calc = Con(calc < 0.0,0.0,calc) #remove negative and null values\n",
    "                calc = Con(IsNull(calc),0, calc) #remove null\n",
    "                outCS = arcpy.SpatialReference('NAD 1983 UTM Zone 12N') #change coordinate units to m for spatial analysis\n",
    "                outnm = outpath+rast[0:4]+str(y).zfill(2)+str(m).zfill(2)+statstype[statistics]\n",
    "                arcpy.ProjectRaster_management(calc, outnm, outCS, 'BILINEAR', outcellsize,\n",
    "                                               'WGS_1984_(ITRF00)_To_NAD_1983', '#', '#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes snow and rain, which are provided as separate data sets in the SNOTEL data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wet Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a measure of the cumulative incoming rain over a month.<br> \n",
    "Units are meters of water per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snowsummary('RAIN', 10000.0, \"SUM\", monthRange=[1, 12], yearRange=[2004, 2014])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the \"dry\" precipitation that falls to the ground as snow.<br>\n",
    "We summed daily data to create cumulative monthly snowfall.<br>\n",
    "Units are in meters of water per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snowsummary('SNOW', 10000.0, \"SUM\", monthRange=[9, 9], yearRange=[2016, 2016])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthRange = [9,9] \n",
    "yearRange = [2016,2016]\n",
    "\n",
    "g = {}\n",
    "path=\"H:/GIS/SNODAS/SNODASproj.gdb/\"\n",
    "arcpy.env.workspace = path\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "for y in range(yearRange[0],yearRange[1]+1): #set years converted here\n",
    "    for m in range(monthRange[0],monthRange[1]+1): #set months converted here\n",
    "        my = str(y)+str(m).zfill(2)\n",
    "        newdn = 'TPPT' + my\n",
    "        try:\n",
    "            calc = Plus('SNOW'+ my +'SUM', 'RAIN'+ my +'SUM')\n",
    "            calc.save(newdn+'SUM')\n",
    "            print(newdn)\n",
    "        except(RuntimeError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWE = Snow-water equivalent;  This is a measure of the estimated total water content of the snow pack. <br>\n",
    "The median is used to summarize these data.<br>\n",
    "Units are in meters of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snowsummary('SWEQ', 1000.0, 'MEDIAN', monthRange=[9, 9], yearRange=[2016, 2016])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowmelt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNML = Cumulative monthly snowmelt calculated by summing daily snowmelt data.<br>\n",
    "Units are in meters of water per month.\n",
    "Snow Melt Runoff at the Base of the Snow Pack.\n",
    "Units are meters of water per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snowsummary('SNML', 100000.0, 'SUM', monthRange=[1, 12], yearRange=[2004, 2014])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow Sublimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BSSB = Cumulative monthly blowing snow sublimation.<br>\n",
    "SPSB = Cumulative monthly snow pack sublimation.<br>\n",
    "TSSB = Total Cumulative monthly snow sublimation.<br>\n",
    "Units are in meters of water per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snowsummary('BSSB', 100000.0, 'SUM', monthRange=[9, 9], yearRange=[2016, 2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snowsummary('SPSB', 100000.0, 'SUM', monthRange=[9, 9], yearRange=[2016, 2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = {}\n",
    "path=\"H:/GIS/SNODAS/SNODASproj.gdb/\"\n",
    "arcpy.env.workspace = path\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "monthRange = [9,9] \n",
    "yearRange = [2016,2016]\n",
    "\n",
    "\n",
    "for y in range(yearRange[0],yearRange[1]+1): #set years converted here\n",
    "    for m in range(monthRange[0],monthRange[1]+1): #set months converted here\n",
    "        my = str(y)+str(m).zfill(2)\n",
    "        newdn = 'TSSB' + my\n",
    "        try:\n",
    "            calc = Plus('BSSB'+ my +'SUM', 'SPSB'+ my +'SUM')\n",
    "            calc.save(newdn+'SUM')\n",
    "            print(newdn)\n",
    "        except(RuntimeError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def totalavg(code, statistics=\"MEAN\", monthRange = [1,12], yearRange = [2003,2016], \n",
    "                path=\"H:/GIS/SNODAS/SNODASproj.gdb/\", outpath=\"H:/GIS/SNODAS/SNODASproj.gdb/\"):\n",
    "    '''\n",
    "    Summarizes daily raster data into monthly data.\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "        code = string with four letters represting data type to summarize (example 'BSSB')\n",
    "        statistics = how data will be summarized; defaults to monthly averages; options are\n",
    "            ['MEAN','MAJORITY','MAXIMUM','MEDIAN','MINIMUM','MINORITY','RANGE','STD','SUM','VARIETY']\n",
    "            Most common are 'MEAN','MEDIAN', and 'SUM'\n",
    "            These are inputs that will be used in the ArcPy CellStatistics function. \n",
    "            See http://pro.arcgis.com/en/pro-app/tool-reference/spatial-analyst/cell-statistics.htm for documentation\n",
    "        monthRange = beginning and end months of summary statistics\n",
    "        yearRange = beginning and end years of summary statistics\n",
    "        path = location of geodatabase of data to summarize\n",
    "        outpath = location of geodatabase where output data should be stored\n",
    "    OUTPUT\n",
    "    ------\n",
    "        summary raster(s) stored in outpath\n",
    "    \n",
    "    '''\n",
    "    g = {}\n",
    "    statstype = {'MEAN':'AVG', 'MAJORITY':'MAJ', 'MAXIMUM':'MAX', 'MEDIAN':'MED', 'MINIMUM':'MIN', 'MINORITY':'MNR', \n",
    "                 'RANGE':'RNG', 'STD':'STD', 'SUM':'SUM', 'VARIETY':'VAR'}\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    \n",
    "    #iterate over month range set here; default is 1 to 12 (Jan to Dec)\n",
    "    for m in range(monthRange[0],monthRange[1]+1): \n",
    "        \n",
    "        #this defines the dictionary key based on data type, month, and year\n",
    "        g[code+'0000'+str(m).zfill(2)] = [] \n",
    "        \n",
    "        #pick all tiff files from raw data folder of a data type\n",
    "        for rast in arcpy.ListRasters():\n",
    "            yrrng = range(yearRange[0],yearRange[1]+1) #set years converted here\n",
    "            \n",
    "            # create a list of rasters with the right code and month and year\n",
    "            if rast[0:4] == code and int(rast[4:8]) in yrrng and int(rast[8:10]) == m:\n",
    "                g[code+'0000'+str(m).zfill(2)].append(rast) #create a list of rasters for each month\n",
    "            else:\n",
    "                pass\n",
    "        if len(g[code+'0000'+str(m).zfill(2)])>0:\n",
    "            \n",
    "            # arcpy sa functions that summarize the daily data to monthly data\n",
    "            calc = CellStatistics(g[code+'0000'+str(m).zfill(2)], statistics_type = statistics, ignore_nodata=\"DATA\")\n",
    "            calc.save(code+'0000'+str(m).zfill(2)+statstype[statistics])\n",
    "            print(code+'0000'+str(m).zfill(2)+statstype[statistics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalavg('TSSB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalavg('SNML', monthRange=[2, 12], yearRange=[2003, 2016])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRISM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRISM Data\n",
    "http://www.prism.oregonstate.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=http://www.prism.oregonstate.edu/documents/PRISM_downloads_web_service.pdf>PRISM Web Services</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthRange = [1,12]\n",
    "\n",
    "fileplace = 'H:/GIS/PRISM/PRISM'\n",
    "\n",
    "for m in range(monthRange[0],monthRange[1]+1): \n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(\"http://services.nacse.org/prism/data/public/normals/800m/ppt/\"+ str(m).zfill(2), \n",
    "                      fileplace+str(m).zfill(2)+'.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testfile = urllib.URLopener()\n",
    "testfile.retrieve(\"http://services.nacse.org/prism/data/public/normals/800m/ppt/\"+ '14', \n",
    "                    fileplace+'14'+'.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileplace = 'H:/GIS/PRISM/PRISM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzipper(filepath):\n",
    "\n",
    "    import zipfile\n",
    "\n",
    "    f = zipfile.ZipFile(filepath,'r')\n",
    "    f.extractall(filepath[:-6])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for files in glob.glob(fileplace+'*.zip'):\n",
    "    unzipper(files)\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthRange = [1,12]\n",
    "\n",
    "fileplace = 'H:/GIS/PRISM/PRISM'\n",
    "\n",
    "for m in range(monthRange[0],monthRange[1]+1): \n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(\"http://services.nacse.org/prism/data/public/normals/800m/ppt/\"+ str(m).zfill(2), \n",
    "                      fileplace+str(m).zfill(2)+'.zip')\n",
    "testfile = urllib.URLopener()\n",
    "testfile.retrieve(\"http://services.nacse.org/prism/data/public/normals/800m/ppt/\"+ 14, \n",
    "                    fileplace+str(m).zfill(2)+'.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates monthly available water:\n",
    "    $$Available\\;water = Rain + Snowmelt$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"H:/GIS/SNODAS.gdb/\"\n",
    "path2 = \"U:/GWP/Groundwater/Projects/BCM/Data/AvailableWater2.gdb/\"\n",
    "\n",
    "def calc_avail_water(path, path2, months='',years='')\n",
    "\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    if months == '':\n",
    "        months = [1,12] \n",
    "    if years == '':\n",
    "        years = [2004,2014]\n",
    "\n",
    "    for y in range(years[0], years[1]+1): #set years converted here\n",
    "        for m in range(months[0], months[1]+1): #set months converted here\n",
    "            my = str(y)+str(m).zfill(2)\n",
    "            newdn = 'AVWT' + my\n",
    "            rain = Raster('RAIN'+ my +'SUM')\n",
    "            melt = Raster('SNML'+ my +'SUM')\n",
    "            calc = rain + melt\n",
    "            calc.save(path2+newdn)\n",
    "            print(newdn)\n",
    "        \n",
    "calc_avail_water(path, path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Soil Water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The calculation of excess water provides the water that is available for watershed hydrology. Available water occupies the soil profile, where water will become actual evapotranspiration,and may result in runoff or recharge, depending on the permeability of the underlying bedrock. Total soil‐water storage is calculated as porosity multiplied by soil depth. Field capacity (soil water volume at ‐0.3 megapascals [MPa]) is the soil water volume below which drainage is negligible, and wilting point (soil water volume at ‐1.5 MPa) is the soil water volume below which actual evapotranspiration does not occur (Hillel 1980).</p>\n",
    "<p>Once available water is calculated, it may exceed total soil storage and become runoff, or it may be less than total soil storage but greater than field capacity and become recharge. Anything less than field capacity will be calculated as actual evapotranspiration at the rate of PET for that month until it reaches wilting point. When soil water is less than total soil storage and greater than field capacity, soil water greater than field capacity equals recharge. If recharge is greater than bedrock permeability (K), then recharge = K and excess becomes runoff, else it will recharge at K until field capacity. Runoff and recharge combine to calculate basin discharge, and actual evapotranspiration is subtracted from PET to calculate climate water deficit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Available\\;Soil\\;Water_{t} = Available\\;Water_{t} + Available\\;Soil\\;Water_{t-1}$$\n",
    "$$Available\\;Soil\\;Water_{t} = Available\\;Soil\\;Water_{t-1} - Runoff_{t} - Recharge_{t} - AET_{t}$$\n",
    "* IF Available Soil Water is greater than Total Soil Water then equation 1<br>\n",
    "* IF Available Soil Water is between Total Soil Water and FC Soil Water then equation 2<br>\n",
    "* IF Available Soil Water is between FC Soil Water and WLT Soil Water then equation 3<br>\n",
    "* IF Available Soil Water is less than WLT Soil Water then equation 4<br>\n",
    "* Current Month Soil Water becomes new Previous Month Soil Water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Equation 1</strong>\n",
    "* Runoff = ((Previous Soil Water + Available Water) - Total Soil Water) + (If recharge > geologic K then (Recharge-geologic K)) \n",
    "* Recharge = (Total Soil Water - FC Soil Water) \n",
    "* AET = PET\n",
    "\n",
    "<strong>Equation 2</strong>\n",
    "* Runoff = (If recharge > geologic K then (Recharge-geologic K)) \n",
    "* Recharge = Soil Water - FC Soil Water\n",
    "* AET = PET\n",
    "\n",
    "<strong>Equation 3</strong>\n",
    "* Runoff = 0\n",
    "* Recharge = 0\n",
    "* AET = PET\n",
    "\n",
    "<strong>Equation 4</strong>\n",
    "* Runoff = 0\n",
    "* Recharge = 0\n",
    "* AET = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://gis.stackexchange.com/questions/95027/multiple-conditional-statement-with-in-a-con-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from arcpy import Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200401\n",
      "200402\n",
      "200403\n",
      "200404\n",
      "200405\n",
      "200406\n",
      "200407\n",
      "200408\n",
      "200409\n",
      "200410\n",
      "200411\n",
      "200412\n",
      "200501\n",
      "200502\n",
      "200503\n",
      "200504\n",
      "200505\n",
      "200506\n",
      "200507\n",
      "200508\n",
      "200509\n",
      "200510\n",
      "200511\n",
      "200512\n",
      "200601\n",
      "200602\n",
      "200603\n",
      "200604\n",
      "200605\n",
      "200606\n",
      "200607\n",
      "200608\n",
      "200609\n",
      "200610\n",
      "200611\n",
      "200612\n",
      "200701\n",
      "200702\n",
      "200703\n",
      "200704\n",
      "200705\n",
      "200706\n",
      "200707\n",
      "200708\n",
      "200709\n",
      "200710\n",
      "200711\n",
      "200712\n",
      "200801\n",
      "200802\n",
      "200803\n",
      "200804\n",
      "200805\n",
      "200806\n",
      "200807\n",
      "200808\n",
      "200809\n",
      "200810\n",
      "200811\n",
      "200812\n",
      "200901\n",
      "200902\n",
      "200903\n",
      "200904\n",
      "200905\n",
      "200906\n",
      "200907\n",
      "200908\n",
      "200909\n",
      "200910\n",
      "200911\n",
      "200912\n",
      "201001\n",
      "201002\n",
      "201003\n",
      "201004\n",
      "201005\n",
      "201006\n",
      "201007\n",
      "201008\n",
      "201009\n",
      "201010\n",
      "201011\n",
      "201012\n",
      "201101\n",
      "201102\n",
      "201103\n",
      "201104\n",
      "201105\n",
      "201106\n",
      "201107\n",
      "201108\n",
      "201109\n",
      "201110\n",
      "201111\n",
      "201112\n",
      "201201\n",
      "201202\n",
      "201203\n",
      "201204\n",
      "201205\n",
      "201206\n",
      "201207\n",
      "201208\n",
      "201209\n",
      "201210\n",
      "201211\n",
      "201212\n",
      "201301\n",
      "201302\n",
      "201303\n",
      "201304\n",
      "201305\n",
      "201306\n",
      "201307\n",
      "201308\n",
      "201309\n",
      "201310\n",
      "201311\n",
      "201312\n",
      "201401\n",
      "201402\n",
      "201403\n",
      "201404\n",
      "201405\n",
      "201406\n",
      "201407\n",
      "201408\n",
      "201409\n",
      "201410\n",
      "201411\n",
      "201412\n"
     ]
    }
   ],
   "source": [
    "monthRange = [1,12] \n",
    "yearRange = [2004,2014]\n",
    "\n",
    "path = \"U:/GWP/Groundwater/Projects/BCM/Data/\"\n",
    "field_cap = Raster(path + \"Soil.gdb/fieldCap\")\n",
    "wilt_point = Raster(path + \"Soil.gdb/WiltPoint\")\n",
    "T_soil_water = Raster(path + \"Soil.gdb/Tsoilwater\")\n",
    "geol_k = Raster(path + \"Soil.gdb/Geol_K\")\n",
    "#geol_k = Raster(path + \"Soil.gdb/BMC_K\")\n",
    "avail_water = \"U:/GWP/Groundwater/Projects/BCM/Data/AvailableWater2.gdb/\"\n",
    "pet = path+'MODIS16.gdb/'\n",
    "\n",
    "results = \"U:/GWP/Groundwater/Projects/BCM/Data/Results.gdb/\"\n",
    "    \n",
    "def UBM_calc(results, field_cap, wilt_point, T_soil_water, geol_k, avail_water, pet, months = '', years = ''):\n",
    "    \n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    if months == '':\n",
    "        months = [1,12] \n",
    "    if years == '':\n",
    "        years = [2004,2014]\n",
    "\n",
    "    av_soil_water = field_cap\n",
    "    for y in range(years[0],years[1]+1): #set years converted here\n",
    "        for m in range(months[0],months[1]+1): #set months converted here\n",
    "            my = str(y) + str(m).zfill(2)\n",
    "            av_wtr = Raster(avail_water+'AVWT'+ my)\n",
    "            pet_rast = Raster(pet + 'PET'+ my) \n",
    "\n",
    "            av_soil_water = av_wtr + av_soil_water\n",
    "\n",
    "            #Eq 1\n",
    "            av_recharge1 = \"T_soil_water - field_cap\"\n",
    "            recharge1 = \"Con(eval(av_recharge1) > geol_k, geol_k, eval(av_recharge1))\"\n",
    "            runoff1 = \"(av_soil_water - T_soil_water) + Con(eval(av_recharge1) > geol_k, eval(av_recharge1) - geol_k, 0)\"\n",
    "            #Eq2\n",
    "            av_recharge2 = \"av_soil_water - field_cap\"\n",
    "            recharge2 = \"Con(eval(av_recharge2) > geol_k, geol_k, eval(av_recharge2))\"\n",
    "            runoff2 = \"Con(eval(av_recharge2) > geol_k, eval(av_recharge2) - geol_k, 0)\"\n",
    "            #Eq3 recharge3 = 0 runoff3 = 0 aet = pet_rast\n",
    "            #Eq4 recharge3 = 0 runoff3 = 0 aet = 0\n",
    "\n",
    "            #Order of if/then is Eq 1, Eq 4, Eq 2, Eq 3\n",
    "            recharge = Con(av_soil_water > T_soil_water, eval(recharge1), \n",
    "                      Con(av_soil_water < wilt_point, 0,\n",
    "                         Con((av_soil_water < T_soil_water) & (av_soil_water > field_cap), eval(recharge2),\n",
    "                            Con((av_soil_water > wilt_point) & (av_soil_water < field_cap), 0, 0))))\n",
    "            recharge.save(results + 'rec' + my)\n",
    "\n",
    "            runoff = Con(av_soil_water > T_soil_water, eval(runoff1), \n",
    "                      Con(av_soil_water < wilt_point, 0,\n",
    "                         Con((av_soil_water < T_soil_water) & (av_soil_water > field_cap), eval(runoff2),\n",
    "                            Con((av_soil_water > wilt_point) & (av_soil_water < field_cap), 0, 0))))\n",
    "            runoff.save(results + 'run' + my)\n",
    "\n",
    "            aet = Con(av_soil_water > T_soil_water, pet_rast, \n",
    "                      Con(av_soil_water < wilt_point, 0,\n",
    "                         Con((av_soil_water < T_soil_water) & (av_soil_water > field_cap), pet_rast,\n",
    "                            Con((av_soil_water > wilt_point) & (av_soil_water < field_cap), pet_rast,0))))\n",
    "            aet.save(results + 'aet' + my)\n",
    "\n",
    "            av_soil_water = av_soil_water - runoff - recharge - aet\n",
    "            av_soil_water = Con(av_soil_water > 0.0, av_soil_water, 0.0)\n",
    "            av_soil_water.save(results + 'asw' + my)\n",
    "            print(my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from arcpy import env  \n",
    "env.overwriteOutput = True  \n",
    "env.workspace = \"C:/Users/PAULINKENBRANDT/AppData/Roaming/ESRI/Desktop10.4/ArcCatalog/AGRC_SGID.sde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def monthly_to_yearly(path, code, yearRange='', statistics='SUM'):\n",
    "    if yearRange=='':\n",
    "        yearRange = [2004,2014]\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    for y in range(yearRange[0],yearRange[1]+1): #set years converted here\n",
    "        ylist = arcpy.ListRasters(code+str(y)+\"*\") #pick all files from raw data folder of a data type\n",
    "        calc = CellStatistics(ylist, statistics_type = statistics, ignore_nodata=\"DATA\")\n",
    "        outnm = 'y'+code+str(y)\n",
    "        desc = arcpy.Describe(calc)\n",
    "        print(outnm)\n",
    "        calc.save(outnm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize(path, code, statistics='MEAN'):\n",
    "    arcpy.env.workspace = path\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    rlist = arcpy.ListRasters(code+\"*\") #pick all files from raw data folder of a data type\n",
    "    # arcpy sa functions that summarize the daily data to monthly data\n",
    "    calc = CellStatistics(rlist, statistics_type = statistics, ignore_nodata=\"DATA\")\n",
    "    outnm = code+\"_\"+statistics\n",
    "    calc.save(outnm)\n",
    "    print(outnm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'RasterDataset', 'yrec2004')\n",
      "(u'RasterDataset', 'yrec2005')\n",
      "(u'RasterDataset', 'yrec2006')\n",
      "(u'RasterDataset', 'yrec2007')\n",
      "(u'RasterDataset', 'yrec2008')\n",
      "(u'RasterDataset', 'yrec2009')\n",
      "(u'RasterDataset', 'yrec2010')\n",
      "(u'RasterDataset', 'yrec2011')\n",
      "(u'RasterDataset', 'yrec2012')\n",
      "(u'RasterDataset', 'yrec2013')\n",
      "(u'RasterDataset', 'yrec2014')\n"
     ]
    }
   ],
   "source": [
    "path = 'H:/GIS/Results.gdb'\n",
    "code = 'rec'\n",
    "monthly_to_yearly(path,code)\n",
    "#summarize(path,code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yrec_MEAN', <type 'Raster'>)\n"
     ]
    }
   ],
   "source": [
    "code = 'yrec'\n",
    "summarize(path,code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'RasterDataset', 'yrun2004')\n",
      "(u'RasterDataset', 'yrun2005')\n",
      "(u'RasterDataset', 'yrun2006')\n",
      "(u'RasterDataset', 'yrun2007')\n",
      "(u'RasterDataset', 'yrun2008')\n",
      "(u'RasterDataset', 'yrun2009')\n",
      "(u'RasterDataset', 'yrun2010')\n",
      "(u'RasterDataset', 'yrun2011')\n",
      "(u'RasterDataset', 'yrun2012')\n",
      "(u'RasterDataset', 'yrun2013')\n",
      "(u'RasterDataset', 'yrun2014')\n",
      "('yrun_MEAN', <type 'Raster'>)\n"
     ]
    }
   ],
   "source": [
    "path = 'H:/GIS/Results.gdb'\n",
    "code = 'run'\n",
    "monthly_to_yearly(path,code)\n",
    "code = 'yrun'\n",
    "summarize(path,code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
